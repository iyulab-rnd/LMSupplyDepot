### Variables
@baseUrl = https://localhost:7212
@apiBase = {{baseUrl}}/api/models

### Explicitly load a model
POST {{apiBase}}/load
Content-Type: application/json

{
  "model": "llama-3-8b",
  "parameters": {
    "gpu_layers": 26,
    "threads": 4,
    "context_size": 4096,
    "batch_size": 512
  }
}

### Explicitly load a model with alias
POST {{apiBase}}/load
Content-Type: application/json

{
  "model": "my-llama-alias",
  "parameters": {
    "gpu_layers": 0,  // CPU only mode
    "threads": 8
  }
}

### Unload a model
POST {{apiBase}}/unload
Content-Type: application/json

{
  "model": "llama-3-8b"
}

### Get all currently loaded models
GET {{apiBase}}/loaded
Accept: application/json